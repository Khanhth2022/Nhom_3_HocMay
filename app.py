import streamlit as st
import pandas as pd
import joblib
import numpy as np
import os
import imblearn

# --- 1. C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="D·ª± ƒëo√°n R·ªùi b·ªè", layout="wide")

# Danh s√°ch file model (ƒê·∫£m b·∫£o c√°c file n√†y n·∫±m c√πng th∆∞ m·ª•c g·ªëc tr√™n GitHub)
MODEL_FILES = {
    "Stacking (M√¥ h√¨nh t·ªïng h·ª£p)": "stacking_model.pkl",
    "Decision Tree (C√¢y quy·∫øt ƒë·ªãnh)": "decision_tree_model.pkl",
    "Logistic Regression (H·ªìi quy)": "logistic_regression_model.pkl",
    "Perceptron (M·∫°ng n∆°-ron ƒë∆°n gi·∫£n)": "perceptron_model.pkl"
}

# --- 2. GIAO DI·ªÜN SIDEBAR ---
st.sidebar.header("‚öôÔ∏è C·∫•u h√¨nh h·ªá th·ªëng")
selected_model_name = st.sidebar.selectbox("Ch·ªçn thu·∫≠t to√°n d·ª± ƒëo√°n:", list(MODEL_FILES.keys()))
selected_file = MODEL_FILES[selected_model_name]

# --- 3. H√ÄM T·∫¢I M√î H√åNH (S·ª¨A L·ªñI PICKLE) ---
@st.cache_resource
def load_specific_model(filename):
    if not os.path.exists(filename):
        return None
    try:
        # T·∫£i g√≥i d·ªØ li·ªáu ƒë√£ l∆∞u
        return joblib.load(filename)
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc file model: {e}")
        return None

data = load_specific_model(selected_file)

if data is None:
    st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file '{selected_file}'. H√£y ki·ªÉm tra l·∫°i th∆∞ m·ª•c tr√™n GitHub.")
    st.stop()

# Gi·∫£i n√©n c√°c th√†nh ph·∫ßn
current_model = data['model']
scaler = data['scaler']
model_features = data['features']
threshold = data.get('threshold', 0.5)

st.sidebar.success(f"‚úÖ ƒê√£ t·∫£i: {selected_model_name}")
st.sidebar.info(f"üìç Ng∆∞·ª°ng c·∫Øt: {threshold}")

# --- 4. GIAO DI·ªÜN NH·∫¨P LI·ªÜU ---
st.title("üõçÔ∏è D·ª± ƒêo√°n R·ªùi B·ªè Kh√°ch H√†ng")
st.markdown(f"M√¥ h√¨nh hi·ªán t·∫°i: **{selected_model_name}**")
st.divider()

col1, col2 = st.columns(2)
with col1:
    tenure = st.number_input("Th·ªùi gian g·∫Øn b√≥ (Th√°ng)", min_value=0, value=12)
    warehouse_dist = st.number_input("Kho·∫£ng c√°ch t·ª´ kho ƒë·∫øn nh√† (Km)", min_value=0, value=15)
    order_cat = st.selectbox("Danh m·ª•c hay mua", ['Laptop & Accessory', 'Mobile Phone', 'Fashion', 'Grocery', 'Others'])
    complain = st.selectbox("C√≥ t·ª´ng khi·∫øu n·∫°i kh√¥ng?", [0, 1], format_func=lambda x: "C√≥" if x == 1 else "Kh√¥ng")

with col2:
    day_since_last = st.number_input("S·ªë ng√†y t·ª´ l·∫ßn ƒë·∫∑t cu·ªëi", min_value=0, value=5)
    cashback = st.number_input("Ti·ªÅn ho√†n (Cashback)", min_value=0.0, value=150.0)
    gender = st.selectbox("Gi·ªõi t√≠nh", ['Male', 'Female'])
    marital = st.selectbox("T√¨nh tr·∫°ng h√¥n nh√¢n", ['Single', 'Married', 'Divorced'])

with st.expander("Nh·∫≠p th√™m th√¥ng tin chi ti·∫øt (Kh√¥ng b·∫Øt bu·ªôc)"):
    satisfaction = st.slider("ƒêi·ªÉm h√†i l√≤ng (1-5)", 1, 5, 3)
    num_device = st.slider("S·ªë thi·∫øt b·ªã ƒëƒÉng k√Ω", 1, 6, 2)
    pref_payment = st.selectbox("Thanh to√°n ∆∞a th√≠ch", ['Debit Card', 'Credit Card', 'E wallet', 'UPI', 'COD'])
    pref_login = st.selectbox("Thi·∫øt b·ªã hay d√πng", ['Mobile Phone', 'Computer', 'Phone'])
    city_tier = st.selectbox("C·∫•p ƒë·ªô th√†nh ph·ªë", [1, 2, 3])

# --- 5. X·ª¨ L√ù V√Ä D·ª∞ ƒêO√ÅN (PH·∫¶N FIX USERWARNING) ---
if st.button("üöÄ PH√ÇN T√çCH NGAY", type="primary"):
    # 1. T·∫°o DataFrame t·ª´ input
    input_df = pd.DataFrame({
        'Tenure': [tenure],
        'CityTier': [city_tier],
        'WarehouseToHome': [warehouse_dist],
        'PreferredPaymentMode': [pref_payment],
        'Gender': [gender],
        'NumberOfDeviceRegistered': [num_device],
        'PreferedOrderCat': [order_cat],
        'SatisfactionScore': [satisfaction],
        'MaritalStatus': [marital],
        'NumberOfAddress': [2], 
        'Complain': [complain],
        'DaySinceLastOrder': [day_since_last],
        'CashbackAmount': [cashback],
        'PreferredLoginDevice': [pref_login]
    })
    
    # 2. Encoding v√† chu·∫©n h√≥a kh·ªõp v·ªõi m√¥ h√¨nh g·ªëc
    input_df_encoded = pd.get_dummies(input_df)
    input_df_encoded = input_df_encoded.reindex(columns=model_features, fill_value=0)
    
    # 3. Scale d·ªØ li·ªáu (Tr·∫£ v·ªÅ NumPy array)
    input_data_scaled_raw = scaler.transform(input_df_encoded)
    
    # --- C·ªê ƒê·ªäNH L·ªñI T√äN THU·ªòC T√çNH T·∫†I ƒê√ÇY ---
    # Chuy·ªÉn array ng∆∞·ª£c l·∫°i DataFrame k√®m t√™n c·ªôt t·ª´ Scaler
    input_data_final = pd.DataFrame(
        input_data_scaled_raw, 
        columns=scaler.feature_names_in_
    )
    
    # 4. Th·ª±c hi·ªán d·ª± ƒëo√°n
    try:
        # L·∫•y x√°c su·∫•t n·∫øu m√¥ h√¨nh h·ªó tr·ª£
        prob = current_model.predict_proba(input_data_final)[0][1]
        is_churn = 1 if prob >= threshold else 0
        prob_msg = f"(X√°c su·∫•t: {prob:.1%})"
    except AttributeError:
        # Tr∆∞·ªùng h·ª£p Perceptron ho·∫∑c model kh√¥ng c√≥ predict_proba
        is_churn = current_model.predict(input_data_final)[0]
        prob_msg = "(M√¥ h√¨nh n√†y kh√¥ng h·ªó tr·ª£ t√≠nh x√°c su·∫•t)"

    # 5. Hi·ªÉn th·ªã k·∫øt qu·∫£
    st.divider()
    if is_churn == 1:
        st.error(f"‚ö†Ô∏è C·∫¢NH B√ÅO: Kh√°ch h√†ng c√≥ nguy c∆° R·ªúI B·ªé! {prob_msg}")
        if threshold != 0.5:
            st.caption(f"*D·ª±a tr√™n ng∆∞·ª°ng c·∫Øt t·ªëi ∆∞u: {threshold}*")
    else:
        st.success(f"‚úÖ AN TO√ÄN: Kh√°ch h√†ng kh·∫£ nƒÉng cao s·∫Ω TI·∫æP T·ª§C. {prob_msg}")